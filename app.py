import streamlit as st
import os

# ==========================================
# 1. æ ¸å¿ƒå¼•ç”¨ (Windows ç¨³å®šç‰ˆ)
# ==========================================
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (ä½ åˆšæ‰å·²ç»ä¸‹è½½å¥½äº†)
from langchain_huggingface import HuggingFaceEmbeddings
# âœ… å…³é”®æ›¿æ¢ï¼šä½¿ç”¨ FAISS (Windowsä¸Šç»å¯¹ä¸é—ªé€€ï¼Œä¸”æ”¯æŒæœ¬åœ°ä¿å­˜)
from langchain_community.vectorstores import FAISS

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
# LLM ä¾ç„¶ç”¨äº‘ç«¯ï¼Œä¿è¯å›ç­”è´¨é‡
from langchain_openai import ChatOpenAI

# ==========================================
# 2. é…ç½®åŒºåŸŸ
# ==========================================
os.environ["OPENAI_API_KEY"] = "sk-i0HXYWyGQZ6v5VKdoM0alDBvTpPD8GxVHja1ex6rR0lfP29G"
os.environ["OPENAI_API_BASE"] = "https://api.openai-proxy.org/v1"

# âœ… FAISS ç´¢å¼•ä¿å­˜è·¯å¾„ (å®ç°æ°¸ä¹…è®°å¿†)
INDEX_PATH = "faiss_index_local"

# âœ… æœ¬åœ°æ¨¡å‹åç§° (å’Œä½ åˆšæ‰ä¸‹è½½çš„ä¸€è‡´ï¼Œä¸ä¼šé‡å¤ä¸‹è½½)
LOCAL_MODEL_NAME = "shibing624/text2vec-base-chinese"


# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½
# ==========================================

@st.cache_resource
def load_embedding_model():
    """åŠ è½½æœ¬åœ°æ¨¡å‹"""
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_NAME} ...")
    # å¼ºåˆ¶æŒ‡å®š device='cpu'ï¼Œé¿å¼€æ˜¾å¡æŠ¥é”™
    return HuggingFaceEmbeddings(
        model_name=LOCAL_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )


def process_documents():
    """æ„å»ºçŸ¥è¯†åº“"""
    if not os.path.exists("./data"): return False, "âŒ æ—  data æ–‡ä»¶å¤¹"

    loader = DirectoryLoader('./data', glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    try:
        docs = loader.load()
    except Exception as e:
        return False, f"âŒ è¯»å–å¤±è´¥: {e}"
    if not docs: return False, "âš ï¸ data ä¸ºç©º"

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=80)
    splits = text_splitter.split_documents(docs)

    try:
        # 1. åŠ è½½æœ¬åœ°æ¨¡å‹ (ç§’å¼€)
        embeddings = load_embedding_model()

        # 2. ä½¿ç”¨ FAISS æ„å»ºå‘é‡åº“ (ç»å¯¹ä¸é—ªé€€)
        vectorstore = FAISS.from_documents(splits, embeddings)

        # 3. ä¿å­˜åˆ°ç¡¬ç›˜ (å®ç°è®°å¿†)
        vectorstore.save_local(INDEX_PATH)
        return True, f"âœ… æˆåŠŸæ”¶å½• {len(splits)} æ¡çŸ¥è¯† (æœ¬åœ°æ¨¡å‹+FAISS)"
    except Exception as e:
        return False, f"âŒ æ„å»ºå¤±è´¥: {e}"


def get_chain():
    if not os.path.exists(INDEX_PATH): return None

    embeddings = load_embedding_model()

    try:
        # âœ… åŠ è½½æœ¬åœ° FAISS ç´¢å¼•
        vectorstore = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    except:
        return None

    # æ£€ç´¢å™¨
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

    template = """
        ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„å„¿ç§‘è¿‡æ•ä¸“ç§‘è¥å…»å¸ˆï¼Œåå«â€œæ•å®å®ˆæŠ¤è€…â€ã€‚
        ä½ çš„æœåŠ¡å¯¹è±¡æ˜¯å› å®å®ç‰›å¥¶è›‹ç™½è¿‡æ•ï¼ˆCMPAï¼‰è€Œæ„Ÿåˆ°ç„¦è™‘ã€æ— åŠ©çš„å®¶é•¿ã€‚

        è¯·åŠ¡å¿…ä¸¥æ ¼éµå®ˆä»¥ä¸‹ã€å›ç­”åŸåˆ™ã€‘ï¼š
        1.  **å…±æƒ…å®‰æŠšï¼ˆç¬¬ä¸€ä¼˜å…ˆçº§ï¼‰**ï¼š
            - å¼€åœºè¯·å…ˆå®‰æŠšå®¶é•¿çš„æƒ…ç»ªï¼Œä¾‹å¦‚ï¼šâ€œå®å¦ˆ/å®çˆ¸åˆ«æ€¥ï¼Œè¿‡æ•æ˜¯å®å®å¸¸è§çš„æˆé•¿å°æŒ‘æˆ˜...â€
            - è¯­æ°”è¦æ¸©æŸ”ã€åšå®šï¼Œå¤šç”¨â€œå’±ä»¬å®å®â€ã€â€œå°è‚šè‚šâ€ç­‰äº²åˆ‡è¯æ±‡ã€‚

        2.  **åŸºäºäº‹å®**ï¼š
            - å¿…é¡»ä¸¥æ ¼åŸºäºä¸‹æ–¹çš„ã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ã€‚
            - å¦‚æœèµ„æ–™é‡Œæœ‰æ•°æ®ï¼ˆå¦‚è½¬å¥¶å¤©æ•°ã€å†²æ³¡æ¸©åº¦ï¼‰ï¼Œè¯·ç²¾ç¡®åˆ—å‡ºã€‚

        3.  **é€šä¿—æ˜“æ‡‚ï¼ˆæ¯”å–»æ³•ï¼‰**ï¼š
            - é‡åˆ°ä¸“ä¸šæœ¯è¯­è¦è§£é‡Šã€‚ä¾‹å¦‚ï¼š
              * æŠŠâ€œæ·±åº¦æ°´è§£å¥¶ç²‰â€æ¯”å–»ä¸ºâ€œåˆ‡å¾—å¾ˆç¢çš„é¢æ¡ï¼Œå¥½æ¶ˆåŒ–ä½†è¿˜æœ‰ä¸€ç‚¹ç‚¹å£æ„Ÿâ€ã€‚
              * æŠŠâ€œæ°¨åŸºé…¸å¥¶ç²‰â€æ¯”å–»ä¸ºâ€œå½»åº•ç£¨æˆç²‰çš„é£Ÿç‰©ï¼Œå®Œå…¨æ²¡æœ‰è‡´æ•æ€§â€ã€‚

        4.  **è¯šå®ä¸å®‰å…¨**ï¼š
            - å¦‚æœã€å‚è€ƒèµ„æ–™ã€‘é‡Œæ²¡æœ‰ç­”æ¡ˆï¼Œè¯·è¯šæ³åœ°è¯´ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘çš„çŸ¥è¯†åº“é‡Œæš‚æ—¶æ²¡æŸ¥åˆ°è¿™ç‚¹ï¼Œä¸ºäº†å®å®å®‰å…¨ï¼Œå»ºè®®ç›´æ¥å’¨è¯¢åŒ»ç”Ÿã€‚â€ **ç»å¯¹ä¸è¦çç¼–ï¼**
            - å›ç­”ç»“å°¾å¿…é¡»åŠ ä¸Šï¼šâ€œğŸ’¡ æ¸©é¦¨æç¤ºï¼šä»¥ä¸Šå»ºè®®ä»…ä¾›å‚è€ƒï¼Œå…·ä½“è¯Šç–—æ–¹æ¡ˆè¯·ä»¥åŒ»ç”Ÿé¢è¯Šä¸ºå‡†ã€‚â€

        ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
        {context}

        å®¶é•¿çš„é—®é¢˜ï¼š{question}
        """
    prompt = ChatPromptTemplate.from_template(template)

    def format_docs(docs):
        return "\n\n".join(d.page_content for d in docs)

    chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt | llm | StrOutputParser()
    )
    return chain


# ==========================================
# 4. ç•Œé¢é€»è¾‘
# ==========================================
st.title("ğŸ›¡ï¸ æ•å®å®ˆæŠ¤è€… (Windows æœ€ç»ˆç‰ˆ)")
st.caption("æ¶æ„ï¼šæœ¬åœ° Embedding (CPU) + FAISS æŒä¹…åŒ– + é›¶æˆæœ¬")

with st.sidebar:
    if st.button("ğŸ”„ é‡å»ºçŸ¥è¯†åº“"):
        with st.spinner("æ­£åœ¨å¤„ç†..."):
            s, m = process_documents()
            if s:
                st.success(m)
            else:
                st.error(m)

# âœ… ä¿®å¤ç‚¹ï¼šåˆå§‹åŒ–èŠå¤©è®°å½• (é˜²æ­¢ AttributeError)
if "messages" not in st.session_state:
    st.session_state.messages = []

# âœ… ä¿®å¤ç‚¹ï¼šæ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if input := st.chat_input("è¯·è¾“å…¥é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": input})
    st.chat_message("user").write(input)

    chain = get_chain()
    if chain:
        with st.chat_message("assistant"):
            st.write(chain.invoke(input))
    else:
        st.warning("âš ï¸ è¯·å…ˆé‡å»ºçŸ¥è¯†åº“")